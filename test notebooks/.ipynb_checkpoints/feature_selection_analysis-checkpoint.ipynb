{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f035eb02",
   "metadata": {},
   "source": [
    "# Feature Selection Analysis for Greenhouse Gas Emissions Prediction\n",
    "\n",
    "This notebook analyzes and identifies the best features for predicting Scope 1 and Scope 2 greenhouse gas emissions using various feature selection techniques.\n",
    "\n",
    "## Objectives:\n",
    "- Load and engineer features from the FitchGroup Codeathon dataset\n",
    "- Apply multiple feature selection methods\n",
    "- Compare and rank features by importance\n",
    "- Optimize feature sets for model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f10d4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba7afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for data analysis and feature selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning and Feature Selection\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, f_regression, mutual_info_regression,\n",
    "    RFE, RFECV, VarianceThreshold\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d76e649",
   "metadata": {},
   "source": [
    "## 2. Load and Engineer Features from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b152a9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Training data shape: (429, 12)\n",
      "Test data shape: (49, 10)\n",
      "Sector data shape: (799, 6)\n",
      "Environmental activities shape: (355, 4)\n",
      "SDG data shape: (165, 3)\n",
      "\n",
      "Target Variables Statistics:\n",
      "Scope 1 emissions - Mean: 55745.65, Std: 110535.54\n",
      "Scope 2 emissions - Mean: 57434.75, Std: 177116.18\n",
      "Zero Scope 2 values: 13/429 (3.0%)\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "sector_df = pd.read_csv('data/revenue_distribution_by_sector.csv')\n",
    "env_activities_df = pd.read_csv('data/environmental_activities.csv')\n",
    "sdg_df = pd.read_csv('data/sustainable_development_goals.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Sector data shape: {sector_df.shape}\")\n",
    "print(f\"Environmental activities shape: {env_activities_df.shape}\")\n",
    "print(f\"SDG data shape: {sdg_df.shape}\")\n",
    "\n",
    "# Display basic info about the target variables\n",
    "print(\"\\nTarget Variables Statistics:\")\n",
    "print(f\"Scope 1 emissions - Mean: {train_df['target_scope_1'].mean():.2f}, Std: {train_df['target_scope_1'].std():.2f}\")\n",
    "print(f\"Scope 2 emissions - Mean: {train_df['target_scope_2'].mean():.2f}, Std: {train_df['target_scope_2'].std():.2f}\")\n",
    "print(f\"Zero Scope 2 values: {(train_df['target_scope_2'] == 0).sum()}/{len(train_df)} ({(train_df['target_scope_2'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8ba40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comprehensive feature set...\n",
      "Total features created: 84\n",
      "Feature columns: 81\n",
      "\n",
      "Feature categories created:\n",
      "- Geographic features: 39\n",
      "- Sector features: 22\n",
      "- Environmental features: 6\n",
      "- SDG features: 2\n",
      "- Revenue features: 4\n",
      "- Sustainability features: 5\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Feature Engineering\n",
    "def create_comprehensive_features(train_data, sector_data, env_data, sdg_data):\n",
    "    \"\"\"Create a comprehensive set of engineered features\"\"\"\n",
    "    \n",
    "    # Start with base features\n",
    "    features = train_data.copy()\n",
    "    \n",
    "    # 1. Geographic Features (One-hot encoding)\n",
    "    region_dummies = pd.get_dummies(features['region_code'], prefix='region')\n",
    "    features = pd.concat([features, region_dummies], axis=1)\n",
    "    \n",
    "    # Country diversity (simplified)\n",
    "    country_dummies = pd.get_dummies(features['country_code'], prefix='country')\n",
    "    features = pd.concat([features, country_dummies], axis=1)\n",
    "    \n",
    "    # 2. Revenue-based features\n",
    "    features['log_revenue'] = np.log1p(features['revenue'])\n",
    "    features['revenue_millions'] = features['revenue'] / 1e6\n",
    "    features['revenue_squared'] = features['revenue'] ** 2\n",
    "    \n",
    "    # 3. Sustainability score interactions\n",
    "    features['env_gov_interaction'] = features['environmental_score'] * features['governance_score']\n",
    "    features['overall_env_ratio'] = features['overall_score'] / features['environmental_score']\n",
    "    features['weighted_sustainability'] = (\n",
    "        0.45 * features['environmental_score'] + \n",
    "        0.30 * features['social_score'] + \n",
    "        0.25 * features['governance_score']\n",
    "    )\n",
    "    \n",
    "    # 4. Sector-based features\n",
    "    sector_pivot = sector_data.pivot_table(\n",
    "        values='revenue_pct',\n",
    "        index='entity_id',\n",
    "        columns='nace_level_1_code',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    ).add_prefix('sector_')\n",
    "    \n",
    "    # Sector diversity metrics\n",
    "    sector_counts = sector_data.groupby('entity_id').size().rename('sector_diversity')\n",
    "    sector_max_pct = sector_data.groupby('entity_id')['revenue_pct'].max().rename('max_sector_concentration')\n",
    "    sector_entropy = sector_data.groupby('entity_id')['revenue_pct'].apply(\n",
    "        lambda x: -np.sum(x * np.log(x + 1e-10))\n",
    "    ).rename('sector_entropy')\n",
    "    \n",
    "    # 5. Environmental activities features\n",
    "    env_agg = env_data.groupby('entity_id').agg({\n",
    "        'env_score_adjustment': ['sum', 'mean', 'count', 'std']\n",
    "    }).fillna(0)\n",
    "    env_agg.columns = ['env_adj_sum', 'env_adj_mean', 'env_activities_count', 'env_adj_std']\n",
    "    \n",
    "    # Environmental activity types\n",
    "    env_types = env_data.groupby('entity_id')['activity_type'].nunique().rename('env_activity_types')\n",
    "    \n",
    "    # 6. SDG features\n",
    "    sdg_agg = sdg_data.groupby('entity_id').agg({\n",
    "        'sdg_id': ['count', 'nunique']\n",
    "    }).fillna(0)\n",
    "    sdg_agg.columns = ['sdg_commitments', 'unique_sdgs']\n",
    "    \n",
    "    # Climate-related SDGs (6, 7, 13, 14, 15)\n",
    "    climate_sdgs = sdg_data[sdg_data['sdg_id'].isin([6, 7, 13, 14, 15])]\n",
    "    climate_sdg_count = climate_sdgs.groupby('entity_id').size().rename('climate_sdg_count')\n",
    "    \n",
    "    # Merge all features\n",
    "    features = features.merge(sector_pivot, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(sector_counts, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(sector_max_pct, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(sector_entropy, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(env_agg, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(env_types, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(sdg_agg, left_on='entity_id', right_index=True, how='left')\n",
    "    features = features.merge(climate_sdg_count, left_on='entity_id', right_index=True, how='left')\n",
    "    \n",
    "    # Fill missing values\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create comprehensive feature set\n",
    "print(\"Creating comprehensive feature set...\")\n",
    "feature_data = create_comprehensive_features(train_df, sector_df, env_activities_df, sdg_df)\n",
    "\n",
    "print(f\"Total features created: {feature_data.shape[1]}\")\n",
    "print(f\"Feature columns: {len([col for col in feature_data.columns if col not in ['entity_id', 'target_scope_1', 'target_scope_2']])}\")\n",
    "\n",
    "# Display feature summary\n",
    "print(\"\\nFeature categories created:\")\n",
    "print(f\"- Geographic features: {len([col for col in feature_data.columns if col.startswith(('region_', 'country_'))])}\")\n",
    "print(f\"- Sector features: {len([col for col in feature_data.columns if col.startswith('sector_')])}\")\n",
    "print(f\"- Environmental features: {len([col for col in feature_data.columns if col.startswith('env_')])}\")\n",
    "print(f\"- SDG features: {len([col for col in feature_data.columns if col.startswith(('sdg_', 'climate_'))])}\")\n",
    "print(f\"- Revenue features: {len([col for col in feature_data.columns if 'revenue' in col])}\")\n",
    "print(f\"- Sustainability features: {len([col for col in feature_data.columns if any(x in col for x in ['score', 'sustainability'])])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62cdfc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (429, 42)\n",
      "Features selected: 42\n",
      "\n",
      "First 20 features: ['revenue', 'overall_score', 'environmental_score', 'social_score', 'governance_score', 'log_revenue', 'revenue_millions', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'weighted_sustainability', 'sector_A', 'sector_B', 'sector_C', 'sector_D', 'sector_E', 'sector_F', 'sector_G', 'sector_H', 'sector_I']\n",
      "Last 10 features: ['max_sector_concentration', 'sector_entropy', 'env_adj_sum', 'env_adj_mean', 'env_activities_count', 'env_adj_std', 'env_activity_types', 'sdg_commitments', 'unique_sdgs', 'climate_sdg_count']\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrix and targets\n",
    "X = feature_data.drop(['entity_id', 'target_scope_1', 'target_scope_2', 'region_name', 'country_name'], axis=1, errors='ignore')\n",
    "y_scope1 = feature_data['target_scope_1']\n",
    "y_scope2 = feature_data['target_scope_2']\n",
    "\n",
    "# Remove non-numeric columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X = X[numeric_cols]\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "print(f\"Features selected: {len(X.columns)}\")\n",
    "\n",
    "# Display first few feature names\n",
    "print(f\"\\nFirst 20 features: {list(X.columns[:20])}\")\n",
    "print(f\"Last 10 features: {list(X.columns[-10:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d6fb3",
   "metadata": {},
   "source": [
    "## 3. Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8690b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Univariate Feature Selection...\n",
      "\n",
      "==================================================\n",
      "SCOPE 1 EMISSIONS\n",
      "==================================================\n",
      "Top 15 features by F-regression for Scope 1:\n",
      "                feature   f_score\n",
      "            log_revenue 34.916179\n",
      "               sector_C 21.959245\n",
      "                revenue 15.810581\n",
      "       revenue_millions 15.810581\n",
      "               sector_J 15.627018\n",
      "    environmental_score  6.208024\n",
      "       governance_score  5.523411\n",
      "               sector_B  5.295539\n",
      "               sector_K  4.681352\n",
      "               sector_A  4.050341\n",
      "               sector_M  2.764434\n",
      "               sector_D  2.375778\n",
      "      overall_env_ratio  2.292593\n",
      "weighted_sustainability  2.218115\n",
      "               sector_R  2.217086\n",
      "\n",
      "Top 15 features by Mutual Information for Scope 1:\n",
      "                feature  mi_score\n",
      "            log_revenue  0.148033\n",
      "    environmental_score  0.131114\n",
      "                revenue  0.079880\n",
      "       revenue_millions  0.079879\n",
      "               sector_J  0.078568\n",
      "            env_adj_sum  0.066414\n",
      "           env_adj_mean  0.056709\n",
      "        revenue_squared  0.054628\n",
      "          overall_score  0.044832\n",
      "weighted_sustainability  0.044058\n",
      "               sector_K  0.034158\n",
      "   env_activities_count  0.028667\n",
      "      overall_env_ratio  0.026612\n",
      "               sector_C  0.020858\n",
      "               sector_R  0.019134\n",
      "\n",
      "==================================================\n",
      "SCOPE 2 EMISSIONS\n",
      "==================================================\n",
      "Top 15 features by F-regression for Scope 2:\n",
      "             feature   f_score\n",
      "         log_revenue 19.921891\n",
      "             revenue 15.538849\n",
      "    revenue_millions 15.538849\n",
      "            sector_I 13.124144\n",
      "    governance_score 12.268835\n",
      "            sector_C 11.855315\n",
      "         env_adj_sum  7.819954\n",
      "env_activities_count  5.460953\n",
      "  env_activity_types  5.088871\n",
      " env_gov_interaction  4.197841\n",
      "        env_adj_mean  3.202652\n",
      "         env_adj_std  2.669171\n",
      "            sector_N  2.482551\n",
      "     revenue_squared  2.366986\n",
      "            sector_J  2.354923\n",
      "\n",
      "Top 15 features by Mutual Information for Scope 2:\n",
      "             feature  mi_score\n",
      "    revenue_millions  0.100323\n",
      "             revenue  0.099021\n",
      "     revenue_squared  0.084858\n",
      "         log_revenue  0.067986\n",
      "            sector_C  0.058848\n",
      "    governance_score  0.057515\n",
      "        env_adj_mean  0.035799\n",
      "            sector_N  0.032947\n",
      "            sector_J  0.031657\n",
      "            sector_K  0.030322\n",
      "env_activities_count  0.019850\n",
      "         env_adj_sum  0.015793\n",
      "            sector_Q  0.012351\n",
      "            sector_T  0.011822\n",
      "            sector_M  0.009171\n"
     ]
    }
   ],
   "source": [
    "# Univariate Feature Selection using F-regression and Mutual Information\n",
    "def perform_univariate_selection(X, y, target_name, k=20):\n",
    "    \"\"\"Perform univariate feature selection using multiple methods\"\"\"\n",
    "    \n",
    "    # F-regression test\n",
    "    f_selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_f_selected = f_selector.fit_transform(X, y)\n",
    "    f_scores = f_selector.scores_\n",
    "    f_selected_features = X.columns[f_selector.get_support()]\n",
    "    \n",
    "    # Mutual Information\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=42)\n",
    "    mi_ranking = np.argsort(mi_scores)[::-1]\n",
    "    mi_selected_features = X.columns[mi_ranking[:k]]\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'f_score': f_scores,\n",
    "        'mi_score': mi_scores,\n",
    "        'f_selected': X.columns.isin(f_selected_features),\n",
    "        'mi_selected': X.columns.isin(mi_selected_features)\n",
    "    }).sort_values('f_score', ascending=False)\n",
    "    \n",
    "    return results, f_selected_features, mi_selected_features\n",
    "\n",
    "# Apply univariate selection for both targets\n",
    "print(\"Performing Univariate Feature Selection...\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 1 EMISSIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "univariate_scope1, f_features_s1, mi_features_s1 = perform_univariate_selection(X, y_scope1, \"Scope 1\", k=15)\n",
    "print(f\"Top 15 features by F-regression for Scope 1:\")\n",
    "print(univariate_scope1.head(15)[['feature', 'f_score']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTop 15 features by Mutual Information for Scope 1:\")\n",
    "print(univariate_scope1.nlargest(15, 'mi_score')[['feature', 'mi_score']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 2 EMISSIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "univariate_scope2, f_features_s2, mi_features_s2 = perform_univariate_selection(X, y_scope2, \"Scope 2\", k=15)\n",
    "print(f\"Top 15 features by F-regression for Scope 2:\")\n",
    "print(univariate_scope2.head(15)[['feature', 'f_score']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTop 15 features by Mutual Information for Scope 2:\")\n",
    "print(univariate_scope2.nlargest(15, 'mi_score')[['feature', 'mi_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2908a",
   "metadata": {},
   "source": [
    "## 4. Tree-Based Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49b683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importance Analysis...\n",
      "\n",
      "==================================================\n",
      "SCOPE 1 EMISSIONS - TREE IMPORTANCE\n",
      "==================================================\n",
      "Top 20 features by Random Forest importance for Scope 1:\n",
      "                 feature  importance\n",
      "     environmental_score    0.085806\n",
      "         revenue_squared    0.084110\n",
      "                 revenue    0.068648\n",
      "             log_revenue    0.068187\n",
      "                sector_C    0.066260\n",
      "            social_score    0.060765\n",
      "     env_gov_interaction    0.058677\n",
      "        revenue_millions    0.056891\n",
      "       overall_env_ratio    0.052417\n",
      "                sector_B    0.048584\n",
      " weighted_sustainability    0.040829\n",
      "        governance_score    0.037238\n",
      "           overall_score    0.033129\n",
      "                sector_D    0.030142\n",
      "             env_adj_sum    0.024794\n",
      "            env_adj_mean    0.023960\n",
      "max_sector_concentration    0.020677\n",
      "          sector_entropy    0.015358\n",
      "                sector_I    0.014935\n",
      "                sector_A    0.012718\n",
      "\n",
      "==================================================\n",
      "SCOPE 2 EMISSIONS - TREE IMPORTANCE\n",
      "==================================================\n",
      "Top 20 features by Random Forest importance for Scope 2:\n",
      "                 feature  importance\n",
      "             env_adj_std    0.106922\n",
      "       overall_env_ratio    0.101618\n",
      "                 revenue    0.074642\n",
      "        revenue_millions    0.074593\n",
      "         revenue_squared    0.073850\n",
      "             log_revenue    0.061890\n",
      "                sector_I    0.060560\n",
      "             env_adj_sum    0.057541\n",
      "            social_score    0.051958\n",
      "        governance_score    0.044784\n",
      "     env_gov_interaction    0.043491\n",
      "     environmental_score    0.042239\n",
      "           overall_score    0.038578\n",
      "            env_adj_mean    0.034165\n",
      "                sector_C    0.033590\n",
      " weighted_sustainability    0.032286\n",
      "max_sector_concentration    0.010425\n",
      "          sector_entropy    0.010285\n",
      "             unique_sdgs    0.009901\n",
      "      env_activity_types    0.007950\n",
      "\n",
      "==============================\n",
      "RANDOM FOREST MODEL PERFORMANCE\n",
      "==============================\n",
      "Scope 1 - CV RMSE: 117741.41 (Â±50823.39)\n",
      "Scope 2 - CV RMSE: 204806.83 (Â±121072.00)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Feature Importance\n",
    "def get_tree_importance(X, y, target_name, n_estimators=100):\n",
    "    \"\"\"Get feature importance using Random Forest\"\"\"\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, rf\n",
    "\n",
    "print(\"Random Forest Feature Importance Analysis...\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 1 EMISSIONS - TREE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf_importance_s1, rf_model_s1 = get_tree_importance(X, y_scope1, \"Scope 1\")\n",
    "print(\"Top 20 features by Random Forest importance for Scope 1:\")\n",
    "print(rf_importance_s1.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 2 EMISSIONS - TREE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf_importance_s2, rf_model_s2 = get_tree_importance(X, y_scope2, \"Scope 2\")\n",
    "print(\"Top 20 features by Random Forest importance for Scope 2:\")\n",
    "print(rf_importance_s2.head(20).to_string(index=False))\n",
    "\n",
    "# Cross-validation scores for Random Forest models\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"RANDOM FOREST MODEL PERFORMANCE\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "cv_scores_s1 = cross_val_score(rf_model_s1, X, y_scope1, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_s2 = cross_val_score(rf_model_s2, X, y_scope2, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f\"Scope 1 - CV RMSE: {np.sqrt(-cv_scores_s1.mean()):.2f} (Â±{np.sqrt(-cv_scores_s1).std():.2f})\")\n",
    "print(f\"Scope 2 - CV RMSE: {np.sqrt(-cv_scores_s2.mean()):.2f} (Â±{np.sqrt(-cv_scores_s2).std():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8b7e1",
   "metadata": {},
   "source": [
    "## 5. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fc24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination Analysis...\n",
      "\n",
      "==================================================\n",
      "SCOPE 1 EMISSIONS - RFE ANALYSIS\n",
      "==================================================\n",
      "RFE with Linear Regression - Selected features (15):\n",
      "['revenue', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'sector_C', 'sector_G', 'sector_K', 'sector_M', 'sector_Q', 'sector_diversity', 'max_sector_concentration', 'sector_entropy', 'env_activities_count', 'sdg_commitments', 'unique_sdgs']\n",
      "\n",
      "RFE with Random Forest - Selected features (15):\n",
      "['revenue', 'overall_score', 'environmental_score', 'social_score', 'governance_score', 'log_revenue', 'revenue_millions', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'weighted_sustainability', 'sector_B', 'sector_C', 'sector_entropy', 'env_adj_sum']\n",
      "\n",
      "RFECV with Random Forest - Optimal features (30):\n",
      "Optimal number of features: 30\n",
      "['revenue', 'overall_score', 'environmental_score', 'social_score', 'governance_score', 'log_revenue', 'revenue_millions', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'weighted_sustainability', 'sector_A', 'sector_B', 'sector_C', 'sector_D', 'sector_E', 'sector_G', 'sector_I', 'sector_J', 'sector_M', 'sector_O', 'sector_diversity', 'max_sector_concentration', 'sector_entropy', 'env_adj_sum', 'env_adj_mean', 'env_activities_count', 'env_activity_types', 'sdg_commitments', 'unique_sdgs']\n",
      "\n",
      "==================================================\n",
      "SCOPE 2 EMISSIONS - RFE ANALYSIS\n",
      "==================================================\n",
      "RFE with Linear Regression - Selected features (15):\n",
      "['revenue', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'sector_C', 'sector_G', 'sector_K', 'sector_M', 'sector_Q', 'sector_diversity', 'max_sector_concentration', 'sector_entropy', 'env_activities_count', 'sdg_commitments', 'unique_sdgs']\n",
      "\n",
      "RFE with Random Forest - Selected features (15):\n",
      "['revenue', 'overall_score', 'environmental_score', 'social_score', 'governance_score', 'log_revenue', 'revenue_millions', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'weighted_sustainability', 'sector_C', 'sector_I', 'env_adj_sum', 'env_adj_std']\n",
      "\n",
      "RFECV with Random Forest - Optimal features (18):\n",
      "Optimal number of features: 18\n",
      "['revenue', 'overall_score', 'environmental_score', 'social_score', 'governance_score', 'log_revenue', 'revenue_millions', 'revenue_squared', 'env_gov_interaction', 'overall_env_ratio', 'weighted_sustainability', 'sector_C', 'sector_I', 'max_sector_concentration', 'env_adj_sum', 'env_adj_mean', 'env_activities_count', 'env_adj_std']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination with Cross-Validation\n",
    "def perform_rfe_analysis(X, y, target_name, n_features_to_select=15):\n",
    "    \"\"\"Perform RFE with both Linear and Random Forest estimators\"\"\"\n",
    "    \n",
    "    # RFE with Linear Regression\n",
    "    lr_estimator = LinearRegression()\n",
    "    rfe_lr = RFE(estimator=lr_estimator, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe_lr.fit(X, y)\n",
    "    \n",
    "    # RFE with Random Forest\n",
    "    rf_estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    rfe_rf = RFE(estimator=rf_estimator, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe_rf.fit(X, y)\n",
    "    \n",
    "    # RFECV with Random Forest for optimal number of features\n",
    "    rfecv = RFECV(estimator=RandomForestRegressor(n_estimators=30, random_state=42), \n",
    "                  step=1, cv=5, scoring='neg_mean_squared_error', min_features_to_select=5)\n",
    "    rfecv.fit(X, y)\n",
    "    \n",
    "    # Get selected features\n",
    "    rfe_lr_features = X.columns[rfe_lr.support_]\n",
    "    rfe_rf_features = X.columns[rfe_rf.support_]\n",
    "    rfecv_features = X.columns[rfecv.support_]\n",
    "    \n",
    "    # Get rankings\n",
    "    rfe_lr_ranking = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'ranking': rfe_lr.ranking_,\n",
    "        'selected': rfe_lr.support_\n",
    "    }).sort_values('ranking')\n",
    "    \n",
    "    rfe_rf_ranking = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'ranking': rfe_rf.ranking_,\n",
    "        'selected': rfe_rf.support_\n",
    "    }).sort_values('ranking')\n",
    "    \n",
    "    return (rfe_lr_features, rfe_rf_features, rfecv_features, \n",
    "            rfe_lr_ranking, rfe_rf_ranking, rfecv)\n",
    "\n",
    "print(\"Recursive Feature Elimination Analysis...\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 1 EMISSIONS - RFE ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "(rfe_lr_s1, rfe_rf_s1, rfecv_s1, lr_rank_s1, rf_rank_s1, rfecv_model_s1) = perform_rfe_analysis(X, y_scope1, \"Scope 1\")\n",
    "\n",
    "print(f\"RFE with Linear Regression - Selected features ({len(rfe_lr_s1)}):\")\n",
    "print(list(rfe_lr_s1))\n",
    "\n",
    "print(f\"\\nRFE with Random Forest - Selected features ({len(rfe_rf_s1)}):\")\n",
    "print(list(rfe_rf_s1))\n",
    "\n",
    "print(f\"\\nRFECV with Random Forest - Optimal features ({len(rfecv_s1)}):\")\n",
    "print(f\"Optimal number of features: {rfecv_model_s1.n_features_}\")\n",
    "# print(f\"Best CV score: {max(rfecv_model_s1.grid_scores_):.2f}\")\n",
    "print(list(rfecv_s1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 2 EMISSIONS - RFE ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "(rfe_lr_s2, rfe_rf_s2, rfecv_s2, lr_rank_s2, rf_rank_s2, rfecv_model_s2) = perform_rfe_analysis(X, y_scope2, \"Scope 2\")\n",
    "\n",
    "print(f\"RFE with Linear Regression - Selected features ({len(rfe_lr_s2)}):\")\n",
    "print(list(rfe_lr_s2))\n",
    "\n",
    "print(f\"\\nRFE with Random Forest - Selected features ({len(rfe_rf_s2)}):\")\n",
    "print(list(rfe_rf_s2))\n",
    "\n",
    "print(f\"\\nRFECV with Random Forest - Optimal features ({len(rfecv_s2)}):\")\n",
    "print(f\"Optimal number of features: {rfecv_model_s2.n_features_}\")\n",
    "# print(f\"Best CV score: {max(rfecv_model_s2.grid_scores_):.2f}\")\n",
    "print(list(rfecv_s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11224214",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis and Multicollinearity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d96857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Analysis...\n",
      "\n",
      "============================================================\n",
      "CORRELATION ANALYSIS\n",
      "============================================================\n",
      "Highly correlated feature pairs (|r| > 0.8): 11\n",
      "\n",
      "Top 10 highly correlated pairs:\n",
      "                feature1                feature2  correlation\n",
      "                 revenue        revenue_millions     1.000000\n",
      "         sdg_commitments             unique_sdgs     1.000000\n",
      "           overall_score weighted_sustainability     0.999998\n",
      "max_sector_concentration          sector_entropy    -0.960845\n",
      "    env_activities_count      env_activity_types     0.935654\n",
      "        sector_diversity          sector_entropy     0.900560\n",
      "             env_adj_sum            env_adj_mean     0.892121\n",
      "                 revenue         revenue_squared     0.850544\n",
      "        revenue_millions         revenue_squared     0.850544\n",
      "     environmental_score weighted_sustainability     0.824911\n",
      "\n",
      "==============================\n",
      "TARGET CORRELATIONS\n",
      "==============================\n",
      "\n",
      "Top 15 features correlated with Scope 1 emissions:\n",
      "Feature | Correlation\n",
      "----------------------------------------\n",
      "log_revenue                    |   0.2749\n",
      "sector_C                       |   0.2212\n",
      "revenue                        |   0.1890\n",
      "revenue_millions               |   0.1890\n",
      "environmental_score            |   0.1197\n",
      "sector_B                       |   0.1107\n",
      "sector_A                       |   0.0969\n",
      "sector_D                       |   0.0744\n",
      "weighted_sustainability        |   0.0719\n",
      "overall_score                  |   0.0718\n",
      "sector_E                       |   0.0649\n",
      "revenue_squared                |   0.0561\n",
      "sector_diversity               |   0.0506\n",
      "social_score                   |   0.0465\n",
      "sector_entropy                 |   0.0458\n",
      "\n",
      "Top 15 features correlated with Scope 2 emissions:\n",
      "Feature | Correlation\n",
      "----------------------------------------\n",
      "log_revenue                    |   0.2111\n",
      "revenue_millions               |   0.1874\n",
      "revenue                        |   0.1874\n",
      "sector_I                       |   0.1727\n",
      "sector_C                       |   0.1644\n",
      "env_activities_count           |   0.1124\n",
      "env_activity_types             |   0.1085\n",
      "env_adj_std                    |   0.0788\n",
      "revenue_squared                |   0.0742\n",
      "environmental_score            |   0.0490\n",
      "social_score                   |   0.0342\n",
      "sector_B                       |   0.0164\n",
      "sector_diversity               |   0.0146\n",
      "sector_entropy                 |   0.0055\n",
      "max_sector_concentration       |  -0.0041\n",
      "\n",
      "==============================\n",
      "LOW VARIANCE FEATURE REMOVAL\n",
      "==============================\n",
      "Features removed due to low variance (< 0.01): 8\n",
      "Removed features: ['sector_A', 'sector_B', 'sector_D', 'sector_E', 'sector_O', 'sector_S', 'sector_T', 'env_adj_std']\n",
      "Features remaining after variance filtering: 34\n"
     ]
    }
   ],
   "source": [
    "# Correlation Analysis\n",
    "def analyze_correlations(X, y_scope1, y_scope2, correlation_threshold=0.8):\n",
    "    \"\"\"Analyze feature correlations and identify highly correlated features\"\"\"\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = X.corr()\n",
    "    \n",
    "    # Find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > correlation_threshold:\n",
    "                high_corr_pairs.append({\n",
    "                    'feature1': corr_matrix.columns[i],\n",
    "                    'feature2': corr_matrix.columns[j],\n",
    "                    'correlation': corr_matrix.iloc[i, j]\n",
    "                })\n",
    "    \n",
    "    # Target correlations\n",
    "    target_corr_s1 = X.corrwith(y_scope1).sort_values(ascending=False)\n",
    "    target_corr_s2 = X.corrwith(y_scope2).sort_values(ascending=False)\n",
    "    \n",
    "    # Remove NaN correlations\n",
    "    target_corr_s1 = target_corr_s1.dropna()\n",
    "    target_corr_s2 = target_corr_s2.dropna()\n",
    "    \n",
    "    return corr_matrix, high_corr_pairs, target_corr_s1, target_corr_s2\n",
    "\n",
    "print(\"Correlation Analysis...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "corr_matrix, high_corr_pairs, target_corr_s1, target_corr_s2 = analyze_correlations(X, y_scope1, y_scope2)\n",
    "\n",
    "print(f\"Highly correlated feature pairs (|r| > 0.8): {len(high_corr_pairs)}\")\n",
    "if len(high_corr_pairs) > 0:\n",
    "    print(\"\\nTop 10 highly correlated pairs:\")\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('correlation', key=abs, ascending=False)\n",
    "    print(high_corr_df.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*30)\n",
    "print(\"TARGET CORRELATIONS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "print(f\"\\nTop 15 features correlated with Scope 1 emissions:\")\n",
    "print(\"Feature | Correlation\")\n",
    "print(\"-\" * 40)\n",
    "for feature, corr in target_corr_s1.head(15).items():\n",
    "    print(f\"{feature[:30]:<30} | {corr:8.4f}\")\n",
    "\n",
    "print(f\"\\nTop 15 features correlated with Scope 2 emissions:\")\n",
    "print(\"Feature | Correlation\")\n",
    "print(\"-\" * 40)\n",
    "for feature, corr in target_corr_s2.head(15).items():\n",
    "    print(f\"{feature[:30]:<30} | {corr:8.4f}\")\n",
    "\n",
    "# Variance Threshold - remove low variance features\n",
    "print(f\"\\n\" + \"=\"*30)\n",
    "print(\"LOW VARIANCE FEATURE REMOVAL\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "X_variance_filtered = variance_threshold.fit_transform(X)\n",
    "removed_features = X.columns[~variance_threshold.get_support()]\n",
    "\n",
    "print(f\"Features removed due to low variance (< 0.01): {len(removed_features)}\")\n",
    "if len(removed_features) > 0:\n",
    "    print(f\"Removed features: {list(removed_features)}\")\n",
    "\n",
    "print(f\"Features remaining after variance filtering: {X_variance_filtered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4d34d",
   "metadata": {},
   "source": [
    "## 7. L1/L2 Regularization Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91fcd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 (Lasso) Regularization Feature Selection...\n",
      "\n",
      "==================================================\n",
      "SCOPE 1 EMISSIONS - LASSO SELECTION\n",
      "==================================================\n",
      "Alpha | Features | CV RMSE\n",
      "------------------------------\n",
      "  0.1 |       42 | 249230.80\n",
      "  0.5 |       42 | 249198.34\n",
      "  1.0 |       42 | 249157.97\n",
      "  5.0 |       42 | 248823.44\n",
      " 10.0 |       40 | 247940.94\n",
      "\n",
      "Best alpha for Scope 1: 10.0 (RMSE: 247940.94)\n",
      "Selected features (40):\n",
      " 1. revenue                             (coef: 28022.3750)\n",
      " 2. overall_score                       (coef: -12532.2274)\n",
      " 3. environmental_score                 (coef: -5943.1909)\n",
      " 4. social_score                        (coef: 26574.7940)\n",
      " 5. governance_score                    (coef: -14967.4568)\n",
      " 6. log_revenue                         (coef: 26658.0531)\n",
      " 7. revenue_millions                    (coef: -2120.2085)\n",
      " 8. revenue_squared                     (coef: -22025.3605)\n",
      " 9. env_gov_interaction                 (coef: 55718.0150)\n",
      "10. overall_env_ratio                   (coef: -11002.1266)\n",
      "11. weighted_sustainability             (coef: -44115.4691)\n",
      "12. sector_A                            (coef: 9612.9982)\n",
      "13. sector_B                            (coef: 14795.7524)\n",
      "14. sector_C                            (coef: 29296.5045)\n",
      "15. sector_D                            (coef: 11057.6845)\n",
      "16. sector_E                            (coef: 13387.3627)\n",
      "17. sector_F                            (coef: -3350.3143)\n",
      "18. sector_H                            (coef: 6664.4799)\n",
      "19. sector_I                            (coef: 7062.7153)\n",
      "20. sector_J                            (coef: -12260.3958)\n",
      "21. sector_K                            (coef: -6023.7607)\n",
      "22. sector_L                            (coef: -5779.7958)\n",
      "23. sector_M                            (coef: -1638.6294)\n",
      "24. sector_N                            (coef: -280.3814)\n",
      "25. sector_O                            (coef: -4897.6710)\n",
      "26. sector_P                            (coef: 125.3760)\n",
      "27. sector_R                            (coef: -4436.1185)\n",
      "28. sector_S                            (coef: -8303.0834)\n",
      "29. sector_T                            (coef: 1264.8909)\n",
      "30. sector_diversity                    (coef: -5769.2755)\n",
      "31. max_sector_concentration            (coef: 17130.8396)\n",
      "32. sector_entropy                      (coef: 24097.0552)\n",
      "33. env_adj_sum                         (coef: 4643.9682)\n",
      "34. env_adj_mean                        (coef: -3599.4871)\n",
      "35. env_activities_count                (coef: 17784.7458)\n",
      "36. env_adj_std                         (coef: -5427.8860)\n",
      "37. env_activity_types                  (coef: -19949.0133)\n",
      "38. sdg_commitments                     (coef: -12207.9564)\n",
      "39. unique_sdgs                         (coef:  -0.0000)\n",
      "40. climate_sdg_count                   (coef: 2480.6256)\n",
      "\n",
      "==================================================\n",
      "SCOPE 2 EMISSIONS - LASSO SELECTION\n",
      "==================================================\n",
      "Alpha | Features | CV RMSE\n",
      "------------------------------\n",
      "  0.1 |       42 | 212987.34\n",
      "  0.5 |       42 | 212971.79\n",
      "  1.0 |       42 | 212952.43\n",
      "  5.0 |       42 | 212796.98\n",
      " 10.0 |       42 | 212799.30\n",
      "\n",
      "Best alpha for Scope 2: 5.0 (RMSE: 212796.98)\n",
      "Selected features (42):\n",
      " 1. revenue                             (coef: 77465.2191)\n",
      " 2. overall_score                       (coef: -19444.6148)\n",
      " 3. environmental_score                 (coef: -8481.1369)\n",
      " 4. social_score                        (coef: 18978.8655)\n",
      " 5. governance_score                    (coef: -20750.9668)\n",
      " 6. log_revenue                         (coef: 4249.1707)\n",
      " 7. revenue_millions                    (coef:  14.1752)\n",
      " 8. revenue_squared                     (coef: -52415.5689)\n",
      " 9. env_gov_interaction                 (coef: 43990.3997)\n",
      "10. overall_env_ratio                   (coef: -17739.8781)\n",
      "11. weighted_sustainability             (coef: -39046.4356)\n",
      "12. sector_A                            (coef: -3123.8232)\n",
      "13. sector_B                            (coef: 7360.0645)\n",
      "14. sector_C                            (coef: 30953.7934)\n",
      "15. sector_D                            (coef: 1101.9057)\n",
      "16. sector_E                            (coef: -1587.6211)\n",
      "17. sector_F                            (coef: -5510.8534)\n",
      "18. sector_G                            (coef: -2512.4225)\n",
      "19. sector_H                            (coef: 4864.1932)\n",
      "20. sector_I                            (coef: 36771.1191)\n",
      "21. sector_J                            (coef: -5475.2683)\n",
      "22. sector_K                            (coef: -2212.5500)\n",
      "23. sector_L                            (coef: -7408.0575)\n",
      "24. sector_M                            (coef: 529.9142)\n",
      "25. sector_N                            (coef: -8071.4331)\n",
      "26. sector_O                            (coef:  25.6244)\n",
      "27. sector_P                            (coef: 1036.8833)\n",
      "28. sector_Q                            (coef: -1465.6508)\n",
      "29. sector_R                            (coef: 6818.1332)\n",
      "30. sector_S                            (coef: -14313.6251)\n",
      "31. sector_T                            (coef: -11068.3514)\n",
      "32. sector_diversity                    (coef: 31188.8774)\n",
      "33. max_sector_concentration            (coef: -33897.6877)\n",
      "34. sector_entropy                      (coef: -60135.8974)\n",
      "35. env_adj_sum                         (coef: -37281.4075)\n",
      "36. env_adj_mean                        (coef: 26190.5984)\n",
      "37. env_activities_count                (coef: 14775.1952)\n",
      "38. env_adj_std                         (coef: 2521.7162)\n",
      "39. env_activity_types                  (coef: -7610.8870)\n",
      "40. sdg_commitments                     (coef: -13944.8824)\n",
      "41. unique_sdgs                         (coef:  -0.0000)\n",
      "42. climate_sdg_count                   (coef: 555.6610)\n"
     ]
    }
   ],
   "source": [
    "# L1 (Lasso) Regularization for Feature Selection\n",
    "def lasso_feature_selection(X, y, target_name, alpha_values=[0.1, 0.5, 1.0, 5.0, 10.0]):\n",
    "    \"\"\"Use Lasso regression for feature selection\"\"\"\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        lasso = Lasso(alpha=alpha, random_state=42)\n",
    "        lasso.fit(X_scaled, y)\n",
    "        \n",
    "        # Get non-zero coefficients (selected features)\n",
    "        selected_features = X.columns[lasso.coef_ != 0]\n",
    "        n_features = len(selected_features)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_score = cross_val_score(lasso, X_scaled, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "        \n",
    "        results.append({\n",
    "            'alpha': alpha,\n",
    "            'n_features': n_features,\n",
    "            'cv_rmse': np.sqrt(-cv_score),\n",
    "            'selected_features': selected_features,\n",
    "            'coefficients': lasso.coef_[lasso.coef_ != 0]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"L1 (Lasso) Regularization Feature Selection...\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 1 EMISSIONS - LASSO SELECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lasso_results_s1 = lasso_feature_selection(X, y_scope1, \"Scope 1\")\n",
    "\n",
    "print(\"Alpha | Features | CV RMSE\")\n",
    "print(\"-\" * 30)\n",
    "for result in lasso_results_s1:\n",
    "    print(f\"{result['alpha']:5.1f} | {result['n_features']:8d} | {result['cv_rmse']:7.2f}\")\n",
    "\n",
    "# Best alpha based on CV score\n",
    "best_alpha_s1 = min(lasso_results_s1, key=lambda x: x['cv_rmse'])\n",
    "print(f\"\\nBest alpha for Scope 1: {best_alpha_s1['alpha']} (RMSE: {best_alpha_s1['cv_rmse']:.2f})\")\n",
    "print(f\"Selected features ({len(best_alpha_s1['selected_features'])}):\")\n",
    "for i, (feature, coef) in enumerate(zip(best_alpha_s1['selected_features'], best_alpha_s1['coefficients'])):\n",
    "    print(f\"{i+1:2d}. {feature[:35]:<35} (coef: {coef:8.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCOPE 2 EMISSIONS - LASSO SELECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lasso_results_s2 = lasso_feature_selection(X, y_scope2, \"Scope 2\")\n",
    "\n",
    "print(\"Alpha | Features | CV RMSE\")\n",
    "print(\"-\" * 30)\n",
    "for result in lasso_results_s2:\n",
    "    print(f\"{result['alpha']:5.1f} | {result['n_features']:8d} | {result['cv_rmse']:7.2f}\")\n",
    "\n",
    "# Best alpha based on CV score\n",
    "best_alpha_s2 = min(lasso_results_s2, key=lambda x: x['cv_rmse'])\n",
    "print(f\"\\nBest alpha for Scope 2: {best_alpha_s2['alpha']} (RMSE: {best_alpha_s2['cv_rmse']:.2f})\")\n",
    "print(f\"Selected features ({len(best_alpha_s2['selected_features'])}):\")\n",
    "for i, (feature, coef) in enumerate(zip(best_alpha_s2['selected_features'], best_alpha_s2['coefficients'])):\n",
    "    print(f\"{i+1:2d}. {feature[:35]:<35} (coef: {coef:8.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f83074",
   "metadata": {},
   "source": [
    "## 8. Feature Selection Comparison and Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3a9257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL FEATURE SELECTION CONSENSUS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š SCOPE 1 EMISSIONS - CONSENSUS TOP 20 FEATURES\n",
      "------------------------------------------------------------\n",
      "Rank | Feature | Consensus Score\n",
      "------------------------------------------------------------\n",
      "   1 | log_revenue                         |        12.40\n",
      "   2 | sector_C                            |        11.80\n",
      "   3 | revenue                             |        11.80\n",
      "   4 | environmental_score                 |        11.20\n",
      "   5 | revenue_millions                    |        10.40\n",
      "   6 | sector_B                            |         8.80\n",
      "   7 | revenue_squared                     |         7.60\n",
      "   8 | sector_A                            |         7.00\n",
      "   9 | weighted_sustainability             |         6.80\n",
      "  10 | sector_D                            |         6.80\n",
      "  11 | governance_score                    |         6.60\n",
      "  12 | social_score                        |         6.40\n",
      "  13 | sector_J                            |         6.20\n",
      "  14 | overall_env_ratio                   |         6.00\n",
      "  15 | overall_score                       |         5.80\n",
      "  16 | env_gov_interaction                 |         5.80\n",
      "  17 | sector_E                            |         5.00\n",
      "  18 | sector_M                            |         5.00\n",
      "  19 | sector_diversity                    |         4.60\n",
      "  20 | sector_entropy                      |         4.20\n",
      "\n",
      "ðŸ“Š SCOPE 2 EMISSIONS - CONSENSUS TOP 20 FEATURES\n",
      "------------------------------------------------------------\n",
      "Rank | Feature | Consensus Score\n",
      "------------------------------------------------------------\n",
      "   1 | revenue                             |        12.00\n",
      "   2 | log_revenue                         |        12.00\n",
      "   3 | revenue_millions                    |        11.80\n",
      "   4 | sector_I                            |        10.60\n",
      "   5 | env_adj_std                         |         9.40\n",
      "   6 | sector_C                            |         8.40\n",
      "   7 | revenue_squared                     |         8.00\n",
      "   8 | env_activities_count                |         7.60\n",
      "   9 | governance_score                    |         7.40\n",
      "  10 | env_adj_sum                         |         7.40\n",
      "  11 | overall_env_ratio                   |         6.80\n",
      "  12 | social_score                        |         6.40\n",
      "  13 | env_gov_interaction                 |         6.20\n",
      "  14 | environmental_score                 |         6.00\n",
      "  15 | env_adj_mean                        |         5.40\n",
      "  16 | env_activity_types                  |         5.20\n",
      "  17 | overall_score                       |         4.60\n",
      "  18 | max_sector_concentration            |         4.20\n",
      "  19 | weighted_sustainability             |         4.00\n",
      "  20 | sector_B                            |         2.80\n",
      "\n",
      "ðŸ” FEATURE OVERLAP ANALYSIS\n",
      "----------------------------------------\n",
      "Top 15 Scope 1 features: 15\n",
      "Top 15 Scope 2 features: 15\n",
      "Common features: 9\n",
      "Overlap percentage: 60.0%\n",
      "\n",
      "Common important features:\n",
      " 1. environmental_score\n",
      " 2. governance_score\n",
      " 3. log_revenue\n",
      " 4. overall_env_ratio\n",
      " 5. revenue\n",
      " 6. revenue_millions\n",
      " 7. revenue_squared\n",
      " 8. sector_C\n",
      " 9. social_score\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection Summary and Consensus\n",
    "def create_feature_consensus(X, univariate_s1, rf_importance_s1, best_alpha_s1, rfecv_s1, target_corr_s1, top_n=20):\n",
    "    \"\"\"Create consensus ranking from multiple feature selection methods\"\"\"\n",
    "    \n",
    "    # Initialize scoring dictionary\n",
    "    feature_scores = {feature: 0 for feature in X.columns}\n",
    "    \n",
    "    # Univariate F-test (top 15)\n",
    "    f_top_features = univariate_s1.head(15)['feature'].tolist()\n",
    "    for i, feature in enumerate(f_top_features):\n",
    "        feature_scores[feature] += (15 - i) * 0.2\n",
    "    \n",
    "    # Random Forest Importance (top 15)\n",
    "    rf_top_features = rf_importance_s1.head(15)['feature'].tolist()\n",
    "    for i, feature in enumerate(rf_top_features):\n",
    "        feature_scores[feature] += (15 - i) * 0.2\n",
    "    \n",
    "    # Lasso selected features\n",
    "    lasso_features = best_alpha_s1['selected_features']\n",
    "    for feature in lasso_features:\n",
    "        feature_scores[feature] += 10 * 0.2\n",
    "    \n",
    "    # RFECV selected features\n",
    "    for feature in rfecv_s1:\n",
    "        feature_scores[feature] += 10 * 0.2\n",
    "    \n",
    "    # Target correlation (top 15)\n",
    "    corr_top_features = target_corr_s1.abs().head(15).index.tolist()\n",
    "    for i, feature in enumerate(corr_top_features):\n",
    "        feature_scores[feature] += (15 - i) * 0.2\n",
    "    \n",
    "    # Sort by consensus score\n",
    "    consensus_ranking = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return consensus_ranking[:top_n]\n",
    "\n",
    "print(\"FINAL FEATURE SELECTION CONSENSUS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create consensus for both targets\n",
    "print(\"\\nðŸ“Š SCOPE 1 EMISSIONS - CONSENSUS TOP 20 FEATURES\")\n",
    "print(\"-\" * 60)\n",
    "consensus_s1 = create_feature_consensus(X, univariate_scope1, rf_importance_s1, best_alpha_s1, rfecv_s1, target_corr_s1)\n",
    "\n",
    "print(\"Rank | Feature | Consensus Score\")\n",
    "print(\"-\" * 60)\n",
    "for i, (feature, score) in enumerate(consensus_s1, 1):\n",
    "    print(f\"{i:4d} | {feature[:35]:<35} | {score:12.2f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š SCOPE 2 EMISSIONS - CONSENSUS TOP 20 FEATURES\")\n",
    "print(\"-\" * 60)\n",
    "consensus_s2 = create_feature_consensus(X, univariate_scope2, rf_importance_s2, best_alpha_s2, rfecv_s2, target_corr_s2)\n",
    "\n",
    "print(\"Rank | Feature | Consensus Score\")\n",
    "print(\"-\" * 60)\n",
    "for i, (feature, score) in enumerate(consensus_s2, 1):\n",
    "    print(f\"{i:4d} | {feature[:35]:<35} | {score:12.2f}\")\n",
    "\n",
    "# Feature overlap analysis\n",
    "s1_features = set([f[0] for f in consensus_s1[:15]])\n",
    "s2_features = set([f[0] for f in consensus_s2[:15]])\n",
    "common_features = s1_features.intersection(s2_features)\n",
    "\n",
    "print(f\"\\nðŸ” FEATURE OVERLAP ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Top 15 Scope 1 features: {len(s1_features)}\")\n",
    "print(f\"Top 15 Scope 2 features: {len(s2_features)}\")\n",
    "print(f\"Common features: {len(common_features)}\")\n",
    "print(f\"Overlap percentage: {len(common_features)/15*100:.1f}%\")\n",
    "\n",
    "if len(common_features) > 0:\n",
    "    print(f\"\\nCommon important features:\")\n",
    "    for i, feature in enumerate(sorted(common_features), 1):\n",
    "        print(f\"{i:2d}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac989ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ MODEL PERFORMANCE COMPARISON\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Performance Comparison with Different Feature Sets\n",
    "def evaluate_feature_sets(X, y_scope1, y_scope2):\n",
    "    \"\"\"Evaluate model performance with different feature selection methods\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸš€ MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Define feature sets to test\n",
    "    feature_sets = {\n",
    "        'All Features': X.columns.tolist(),\n",
    "        'Top 15 RF Importance S1': rf_importance_s1.head(15)['feature'].tolist(),\n",
    "        'Top 15 RF Importance S2': rf_importance_s2.head(15)['feature'].tolist(),\n",
    "        'Lasso Selected S1': list(best_alpha_s1['selected_features']),\n",
    "        'Lasso Selected S2': list(best_alpha_s2['selected_features']),\n",
    "        'RFECV S1': list(rfecv_s1),\n",
    "        'RFECV S2': list(rfecv_s2),\n",
    "        'Consensus Top 15 S1': [f[0] for f in consensus_s1[:15]],\n",
    "        'Consensus Top 15 S2': [f[0] for f in consensus_s2[:15]],\n",
    "        'Common Features': list(common_features) if len(common_features) >= 5 else [f[0] for f in consensus_s1[:10]]\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for set_name, features in feature_sets.items():\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Select features that exist in X\n",
    "        valid_features = [f for f in features if f in X.columns]\n",
    "        if len(valid_features) < 3:  # Need at least 3 features\n",
    "            continue\n",
    "            \n",
    "        X_subset = X[valid_features]\n",
    "        \n",
    "        # Random Forest Model\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        \n",
    "        # Cross-validation for Scope 1\n",
    "        cv_scores_s1 = cross_val_score(rf_model, X_subset, y_scope1, cv=5, scoring='neg_mean_squared_error')\n",
    "        rmse_s1 = np.sqrt(-cv_scores_s1.mean())\n",
    "        \n",
    "        # Cross-validation for Scope 2\n",
    "        cv_scores_s2 = cross_val_score(rf_model, X_subset, y_scope2, cv=5, scoring='neg_mean_squared_error')\n",
    "        rmse_s2 = np.sqrt(-cv_scores_s2.mean())\n",
    "        \n",
    "        results.append({\n",
    "            'Feature Set': set_name,\n",
    "            'N Features': len(valid_features),\n",
    "            'Scope 1 RMSE': rmse_s1,\n",
    "            'Scope 2 RMSE': rmse_s2,\n",
    "            'Combined RMSE': (rmse_s1 + rmse_s2) / 2\n",
    "        })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results).sort_values('Combined RMSE')\n",
    "    \n",
    "    print(\"Feature Set Performance (Random Forest, 5-Fold CV):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Feature Set':<20} | {'Features':<8} | {'S1 RMSE':<8} | {'S2 RMSE':<8} | {'Avg RMSE':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        print(f\"{row['Feature Set']:<20} | {row['N Features']:<8d} | {row['Scope 1 RMSE']:<8.2f} | {row['Scope 2 RMSE']:<8.2f} | {row['Combined RMSE']:<8.2f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run performance comparison\n",
    "performance_results = evaluate_feature_sets(X, y_scope1, y_scope2)\n",
    "\n",
    "# Best performing feature set\n",
    "best_set = performance_results.iloc[0]\n",
    "print(f\"\\nðŸ† BEST PERFORMING FEATURE SET:\")\n",
    "print(f\"Method: {best_set['Feature Set']}\")\n",
    "print(f\"Number of features: {best_set['N Features']}\")\n",
    "print(f\"Scope 1 RMSE: {best_set['Scope 1 RMSE']:.2f}\")\n",
    "print(f\"Scope 2 RMSE: {best_set['Scope 2 RMSE']:.2f}\")\n",
    "print(f\"Average RMSE: {best_set['Combined RMSE']:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "print(f\"1. Use '{best_set['Feature Set']}' for optimal performance\")\n",
    "print(f\"2. Focus on {best_set['N Features']} carefully selected features rather than all {X.shape[1]} features\")\n",
    "print(f\"3. Consider ensemble methods combining multiple feature selection approaches\")\n",
    "print(f\"4. Revenue-based features and sector information appear to be key predictors\")\n",
    "print(f\"5. Environmental scores show strong predictive power for emissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac1331",
   "metadata": {},
   "source": [
    "## 9. Export Selected Features for Model Training\n",
    "\n",
    "Based on the analysis above, we'll export the best feature sets for use in your final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export optimal feature sets for final model training\n",
    "import json\n",
    "\n",
    "# Get the best performing feature set from the analysis\n",
    "best_feature_set_name = best_set['Feature Set']\n",
    "if best_feature_set_name == 'Consensus Top 15 S1':\n",
    "    optimal_features_s1 = [f[0] for f in consensus_s1[:15]]\n",
    "    optimal_features_s2 = [f[0] for f in consensus_s2[:15]]\n",
    "elif best_feature_set_name == 'Consensus Top 15 S2':\n",
    "    optimal_features_s1 = [f[0] for f in consensus_s1[:15]]\n",
    "    optimal_features_s2 = [f[0] for f in consensus_s2[:15]]\n",
    "else:\n",
    "    # Default to consensus features\n",
    "    optimal_features_s1 = [f[0] for f in consensus_s1[:15]]\n",
    "    optimal_features_s2 = [f[0] for f in consensus_s2[:15]]\n",
    "\n",
    "# Create feature selection results dictionary\n",
    "feature_selection_results = {\n",
    "    'analysis_summary': {\n",
    "        'total_features_engineered': X.shape[1],\n",
    "        'best_performing_method': best_feature_set_name,\n",
    "        'best_combined_rmse': float(best_set['Combined RMSE']),\n",
    "        'best_scope1_rmse': float(best_set['Scope 1 RMSE']),\n",
    "        'best_scope2_rmse': float(best_set['Scope 2 RMSE'])\n",
    "    },\n",
    "    'optimal_features': {\n",
    "        'scope_1_features': optimal_features_s1,\n",
    "        'scope_2_features': optimal_features_s2,\n",
    "        'common_features': list(common_features) if len(common_features) > 0 else []\n",
    "    },\n",
    "    'method_results': {\n",
    "        'random_forest_top_features_s1': rf_importance_s1.head(10)['feature'].tolist(),\n",
    "        'random_forest_top_features_s2': rf_importance_s2.head(10)['feature'].tolist(),\n",
    "        'lasso_selected_s1': list(best_alpha_s1['selected_features'][:10]),\n",
    "        'lasso_selected_s2': list(best_alpha_s2['selected_features'][:10]),\n",
    "        'univariate_top_s1': univariate_scope1.head(10)['feature'].tolist(),\n",
    "        'univariate_top_s2': univariate_scope2.head(10)['feature'].tolist()\n",
    "    },\n",
    "    'feature_importance_insights': {\n",
    "        'revenue_features_important': any('revenue' in f for f in optimal_features_s1[:5]),\n",
    "        'sector_features_important': any('sector' in f for f in optimal_features_s1[:5]),\n",
    "        'environmental_score_important': any('environmental' in f for f in optimal_features_s1[:5]),\n",
    "        'geographic_features_important': any(any(geo in f for geo in ['region', 'country']) for f in optimal_features_s1[:5])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open('notebooks/feature_selection_results.json', 'w') as f:\n",
    "    json.dump(feature_selection_results, f, indent=2)\n",
    "\n",
    "# Create optimized datasets with selected features\n",
    "X_optimized_s1 = X[optimal_features_s1].copy()\n",
    "X_optimized_s2 = X[optimal_features_s2].copy()\n",
    "\n",
    "# Add entity_id and targets back for easy model training\n",
    "optimized_data_s1 = X_optimized_s1.copy()\n",
    "optimized_data_s1['entity_id'] = feature_data['entity_id']\n",
    "optimized_data_s1['target_scope_1'] = y_scope1\n",
    "\n",
    "optimized_data_s2 = X_optimized_s2.copy()\n",
    "optimized_data_s2['entity_id'] = feature_data['entity_id']\n",
    "optimized_data_s2['target_scope_2'] = y_scope2\n",
    "\n",
    "# Save optimized datasets\n",
    "optimized_data_s1.to_pickle('notebooks/optimized_features_scope1.pkl')\n",
    "optimized_data_s2.to_pickle('notebooks/optimized_features_scope2.pkl')\n",
    "\n",
    "print(\"âœ… FEATURE SELECTION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ðŸ“ Results saved to: 'notebooks/feature_selection_results.json'\")\n",
    "print(f\"ðŸ“ Optimized Scope 1 dataset: 'notebooks/optimized_features_scope1.pkl'\")\n",
    "print(f\"ðŸ“ Optimized Scope 2 dataset: 'notebooks/optimized_features_scope2.pkl'\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ FINAL RECOMMENDATIONS:\")\n",
    "print(f\"â€¢ Use {len(optimal_features_s1)} features for Scope 1 prediction\")\n",
    "print(f\"â€¢ Use {len(optimal_features_s2)} features for Scope 2 prediction\")\n",
    "print(f\"â€¢ Expected performance improvement: {((cv_scores_s1.mean() - best_set['Scope 1 RMSE'])/cv_scores_s1.mean()*100):.1f}% for Scope 1\")\n",
    "print(f\"â€¢ Focus on feature engineering around: revenue, sector exposure, environmental scores\")\n",
    "print(f\"â€¢ Consider ensemble methods combining multiple algorithms\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ TOP 10 MOST IMPORTANT FEATURES FOR EACH TARGET:\")\n",
    "print(\"Scope 1:\", optimal_features_s1[:10])\n",
    "print(\"Scope 2:\", optimal_features_s2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5d701-edc5-4e14-bc28-57e46e0bb433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3abb9-a8fd-4f5b-9359-3fce74393d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
