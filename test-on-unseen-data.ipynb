{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548ae4a6",
   "metadata": {},
   "source": [
    "## 1. Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize']=(10,5)\n",
    "print('âœ… Environment ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c55d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "sect_path = os.path.join(DATA_DIR, 'revenue_distribution_by_sector.csv')\n",
    "env_path = os.path.join(DATA_DIR, 'environmental_activities.csv')\n",
    "sdg_path = os.path.join(DATA_DIR, 'sustainable_development_goals.csv')\n",
    "test = pd.read_csv(test_path)\n",
    "sect = pd.read_csv(sect_path)\n",
    "env = pd.read_csv(env_path)\n",
    "sdg = pd.read_csv(sdg_path) if os.path.exists(sdg_path) else pd.DataFrame()\n",
    "print(f'Test Shape: {test.shape}; Sector rows: {sect.shape[0]}; Env rows: {env.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab814c8",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering Helpers (Mirrors Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df_main, df_sect, df_env, df_sdg):\n",
    "    df = df_main.copy()\n",
    "    high_emission_sectors = ['B','C','D','H']\n",
    "    df_sect = df_sect.copy()\n",
    "    df_sect['is_high_intensity'] = df_sect['nace_level_1_code'].isin(high_emission_sectors)\n",
    "    intensity_feat = df_sect.groupby('entity_id').apply(\n",
    "        lambda x: (x['revenue_pct'] * x['is_high_intensity']).sum()\n",
    "    ).to_frame('high_intensity_revenue_share')\n",
    "    env_feats = df_env.groupby('entity_id').agg(\n",
    "        env_activity_count=('activity_code','count'),\n",
    "        env_net_adj=('env_score_adjustment','sum')\n",
    "    )\n",
    "    df = (\n",
    "        df.merge(intensity_feat, on='entity_id', how='left')\n",
    "          .merge(env_feats, on='entity_id', how='left')\n",
    "    )\n",
    "    df['high_intensity_revenue_share'] = df['high_intensity_revenue_share'].fillna(0)\n",
    "    df['env_activity_count'] = df['env_activity_count'].fillna(0)\n",
    "    df['env_net_adj'] = df['env_net_adj'].fillna(0)\n",
    "    df['log_revenue'] = np.log1p(df['revenue'])\n",
    "    df['log_rev_x_intensity'] = df['log_revenue'] * df['high_intensity_revenue_share']\n",
    "    known_regions = ['ANZ','CAR','EA','EEU','LATAM','NAM','WEU']\n",
    "    for region in known_regions:\n",
    "        df[f'log_rev_x_region_{region}'] = df['log_revenue'] * (df['region_code'] == region).astype(int)\n",
    "    df['soc_env_gap'] = df['social_score'] - df['environmental_score']\n",
    "    return df\n",
    "\n",
    "def add_target_encoding(df, df_sect, mapping):\n",
    "    dom = df_sect.sort_values('revenue_pct', ascending=False).drop_duplicates('entity_id')\n",
    "    df = df.merge(dom[['entity_id','nace_level_1_code']], on='entity_id', how='left')\n",
    "    df['sector_implied_target'] = df['nace_level_1_code'].map(mapping).fillna(df['log_revenue'])\n",
    "    return df.drop(columns=['nace_level_1_code'])\n",
    "print('âœ… Feature engineering helpers ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2deefa1",
   "metadata": {},
   "source": [
    "## 4. Load Persisted Models & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c862d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s1 = joblib.load('models/model_scope1_base.joblib')\n",
    "model_s2 = joblib.load('models/model_scope2_base.joblib')\n",
    "model_te_s1 = joblib.load('models/model_scope1_te.joblib')\n",
    "with open('models/sector_mapping_s1.json') as f: sector_map = json.load(f)\n",
    "with open('models/blend_config.json') as f: blend_cfg = json.load(f)\n",
    "print('âœ… Models & mappings loaded.')\n",
    "blend_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc02e3",
   "metadata": {},
   "source": [
    "## 5. Engineer Features for Unseen Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac71d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_base = engineer_features(test, sect, env, sdg)\n",
    "X_test_te = add_target_encoding(X_test_base, sect, sector_map)\n",
    "print(f'Engineered feature shape (base): {X_test_base.shape}; with TE: {X_test_te.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9effa21",
   "metadata": {},
   "source": [
    "## 6. Predict & Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s1_base_log = model_s1.predict(X_test_base)\n",
    "p_s2_base_log = model_s2.predict(X_test_base)\n",
    "p_s1_te_log = model_te_s1.predict(X_test_te)\n",
    "# Invert log1p transformation\n",
    "p_s1_base = np.expm1(p_s1_base_log)\n",
    "p_s1_te = np.expm1(p_s1_te_log)\n",
    "p_s2_base = np.expm1(p_s2_base_log)\n",
    "w_base = blend_cfg['scope1_blend_weights']['base']\n",
    "w_te = blend_cfg['scope1_blend_weights']['target_encoded']\n",
    "final_s1 = w_base * p_s1_base + w_te * p_s1_te\n",
    "final_s2 = p_s2_base  # base only per config\n",
    "inference_submission = pd.DataFrame({'entity_id': test['entity_id'], 'target_scope_1': final_s1, 'target_scope_2': final_s2})\n",
    "inference_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03686021",
   "metadata": {},
   "source": [
    "## 7. Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3228079",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_submission.to_csv('inference_submission.csv', index=False)\n",
    "print('ðŸ’¾ Saved predictions to inference_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c767032",
   "metadata": {},
   "source": [
    "## 8. Diagnostics (Feature Importance & Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76568a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_numeric_names(df):\n",
    "    return [c for c in df.select_dtypes(include=['number']).columns if c not in ['entity_id']]\n",
    "feat_names = quick_numeric_names(X_test_base)\n",
    "imps = model_s1.named_steps['est'].feature_importances_[:len(feat_names)]\n",
    "imp_df = pd.DataFrame({'Feature': feat_names[:len(imps)], 'Importance': imps}).sort_values('Importance', ascending=False).head(10)\n",
    "plt.figure(figsize=(8,4)); sns.barplot(x='Importance', y='Feature', data=imp_df, palette='viridis'); plt.title('Top Scope 1 Predictors (Base)'); plt.show()\n",
    "sns.histplot(final_s1, bins=30, color='steelblue'); plt.title('Distribution: Predicted Scope 1'); plt.show()\n",
    "sns.histplot(final_s2, bins=30, color='darkorange'); plt.title('Distribution: Predicted Scope 2'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d3007",
   "metadata": {},
   "source": [
    "## 9. Completion\n",
    "Inference complete. Provide `inference_submission.csv` as your output."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
