{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61b697f-f99d-44cb-88f7-537b2c034fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "sustain = pd.read_csv(\"./data/sustainable_development_goals.csv\")\n",
    "revenue = pd.read_csv(\"./data/revenue_distribution_by_sector.csv\")\n",
    "environment = pd.read_csv(\"./data/environmental_activities.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2359ecf5-c401-417c-b58d-806362914283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 12)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(sect.isnull().sum())\n",
    "# print(revenue.isnull().sum())\n",
    "# print(environment.isnull().sum())\n",
    "train.shape\n",
    "# test.shape\n",
    "# sustain.shape\n",
    "# revenue.shape\n",
    "# environment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f24ac8e-3f3e-41a1-ba82-cb77ae6efa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "test_ids=set(test['entity_id'].unique())\n",
    "train_ids=set(train['entity_id'].unique())\n",
    "\n",
    "sustain_ids = set(sustain['entity_id'].unique())\n",
    "revenue_ids = set(revenue['entity_id'].unique())\n",
    "env_ids = set(environment['entity_id'].unique())\n",
    "\n",
    "sustain_Test_diff = sustain_ids.difference(train_ids)\n",
    "print(len(test_ids.difference(train_ids)))\n",
    "#test data is completely different from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d69f15b9-63b6-47af-8100-a1cdf2bc92a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "rev_Test_diff = revenue_ids.difference(test_ids)\n",
    "print(len(rev_Test_diff))\n",
    "print(train_ids.difference(rev_Test_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a297b1d3-65a5-4cad-9727-c2201a61619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "sustain_Test_diff = sustain_ids.difference(train_ids)\n",
    "print(sustain_Test_diff.difference(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51f05529-4b4b-48a5-a865-0ec7ae3382a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entities in train: 429\n",
      "Unique entities in test: 49\n",
      "Unique entities in sustain_distribution: 130\n",
      "\n",
      "============================================================\n",
      "COVERAGE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "TRAIN dataset:\n",
      "  Entities WITH sustain data: 118 (27.51%)\n",
      "  Entities WITHOUT sustain data: 311 (72.49%)\n",
      "\n",
      "TEST dataset:\n",
      "  Entities WITH sustain data: 12 (24.49%)\n",
      "  Entities WITHOUT sustain data: 37 (75.51%)\n",
      "\n",
      "Entities in sustain table but NOT in train/test: 0\n",
      "\n",
      "============================================================\n",
      "IMPLICATIONS\n",
      "============================================================\n",
      "\n",
      "âš  IMPORTANT: Some entities don't have sustain distribution data!\n",
      "\n",
      "When merging, you have TWO options:\n",
      "\n",
      "OPTION 1: Left join + Fill missing values with defaults\n",
      "  - Use how='left' when merging\n",
      "  - Fill NaN values with appropriate defaults:\n",
      "    â€¢ Numeric features (HHI, percentages): 0 or median\n",
      "    â€¢ Categorical (dominant sector): 'UNKNOWN' or most common\n",
      "  - Create a 'missing_sustain_data' flag feature\n",
      "\n",
      "OPTION 2: Inner join (only use entities with complete data)\n",
      "  - Use how='inner' when merging\n",
      "  - Loses entities without sustain data\n",
      "  - Would lose 311 train and 37 test samples\n",
      "\n",
      "ðŸ’¡ RECOMMENDATION:\n",
      "  Use OPTION 1 (left join + imputation) because:\n",
      "  - You need to predict ALL test entities\n",
      "  - Missing sustain data itself might be a signal\n",
      "  - Can't afford to lose test samples\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - sustainable_development_goals CHECKING SUSTAINABLE DISTRIBUTION COVERAGE\n",
    "\n",
    "# Get unique entity_ids from each dataset\n",
    "train_entities = set(train['entity_id'].unique())\n",
    "test_entities = set(test['entity_id'].unique())\n",
    "sustain_entities = set(sustain['entity_id'].unique())\n",
    "\n",
    "print(f\"Unique entities in train: {len(train_entities):,}\")\n",
    "print(f\"Unique entities in test: {len(test_entities):,}\")\n",
    "print(f\"Unique entities in sustain_distribution: {len(sustain_entities):,}\")\n",
    "\n",
    "# Check coverage\n",
    "train_covered = train_entities & sustain_entities\n",
    "test_covered = test_entities & sustain_entities\n",
    "\n",
    "train_missing = train_entities - sustain_entities\n",
    "test_missing = test_entities - sustain_entities\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COVERAGE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTRAIN dataset:\")\n",
    "print(f\"  Entities WITH sustain data: {len(train_covered):,} ({len(train_covered)/len(train_entities)*100:.2f}%)\")\n",
    "print(f\"  Entities WITHOUT sustain data: {len(train_missing):,} ({len(train_missing)/len(train_entities)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTEST dataset:\")\n",
    "print(f\"  Entities WITH sustain data: {len(test_covered):,} ({len(test_covered)/len(test_entities)*100:.2f}%)\")\n",
    "print(f\"  Entities WITHOUT sustain data: {len(test_missing):,} ({len(test_missing)/len(test_entities)*100:.2f}%)\")\n",
    "\n",
    "# Check if there are entities in sustain table that aren't in train/test\n",
    "orphan_entities = sustain_entities - train_entities - test_entities\n",
    "print(f\"\\nEntities in sustain table but NOT in train/test: {len(orphan_entities):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPLICATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(train_missing) > 0 or len(test_missing) > 0:\n",
    "    print(\"\\nâš  IMPORTANT: Some entities don't have sustain distribution data!\")\n",
    "    print(\"\\nWhen merging, you have TWO options:\\n\")\n",
    "    \n",
    "    print(\"OPTION 1: Left join + Fill missing values with defaults\")\n",
    "    print(\"  - Use how='left' when merging\")\n",
    "    print(\"  - Fill NaN values with appropriate defaults:\")\n",
    "    print(\"    â€¢ Numeric features (HHI, percentages): 0 or median\")\n",
    "    print(\"    â€¢ Categorical (dominant sector): 'UNKNOWN' or most common\")\n",
    "    print(\"  - Create a 'missing_sustain_data' flag feature\")\n",
    "    \n",
    "    print(\"\\nOPTION 2: Inner join (only use entities with complete data)\")\n",
    "    print(\"  - Use how='inner' when merging\")\n",
    "    print(\"  - Loses entities without sustain data\")\n",
    "    print(f\"  - Would lose {len(train_missing)} train and {len(test_missing)} test samples\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ RECOMMENDATION:\")\n",
    "    print(\"  Use OPTION 1 (left join + imputation) because:\")\n",
    "    print(\"  - You need to predict ALL test entities\")\n",
    "    print(\"  - Missing sustain data itself might be a signal\")\n",
    "    print(\"  - Can't afford to lose test samples\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Perfect coverage! All entities have sustain distribution data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53974905-1929-410a-90f2-3af795a97087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entities in train: 429\n",
      "Unique entities in test: 49\n",
      "Unique entities in environment_distribution: 260\n",
      "\n",
      "============================================================\n",
      "COVERAGE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "TRAIN dataset:\n",
      "  Entities WITH environment data: 237 (55.24%)\n",
      "  Entities WITHOUT environment data: 192 (44.76%)\n",
      "\n",
      "TEST dataset:\n",
      "  Entities WITH environment data: 23 (46.94%)\n",
      "  Entities WITHOUT environment data: 26 (53.06%)\n",
      "\n",
      "Entities in environment table but NOT in train/test: 0\n",
      "\n",
      "============================================================\n",
      "IMPLICATIONS\n",
      "============================================================\n",
      "\n",
      "âš  IMPORTANT: Some entities don't have environment distribution data!\n",
      "\n",
      "When merging, you have TWO options:\n",
      "\n",
      "OPTION 1: Left join + Fill missing values with defaults\n",
      "  - Use how='left' when merging\n",
      "  - Fill NaN values with appropriate defaults:\n",
      "    â€¢ Numeric features (HHI, percentages): 0 or median\n",
      "    â€¢ Categorical (dominant sector): 'UNKNOWN' or most common\n",
      "  - Create a 'missing_environment_data' flag feature\n",
      "\n",
      "OPTION 2: Inner join (only use entities with complete data)\n",
      "  - Use how='inner' when merging\n",
      "  - Loses entities without environment data\n",
      "  - Would lose 192 train and 26 test samples\n",
      "\n",
      "ðŸ’¡ RECOMMENDATION:\n",
      "  Use OPTION 1 (left join + imputation) because:\n",
      "  - You need to predict ALL test entities\n",
      "  - Missing environment data itself might be a signal\n",
      "  - Can't afford to lose test samples\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering - environmental_activities_df\n",
    "# CHECKING ENVIRONMENT DISTRIBUTION COVERAGE\n",
    "\n",
    "# Get unique entity_ids from each dataset\n",
    "environment_entities = set(environment['entity_id'].unique())\n",
    "\n",
    "print(f\"Unique entities in train: {len(train_entities):,}\")\n",
    "print(f\"Unique entities in test: {len(test_entities):,}\")\n",
    "print(f\"Unique entities in environment_distribution: {len(environment_entities):,}\")\n",
    "\n",
    "# Check coverage\n",
    "train_covered = train_entities & environment_entities\n",
    "test_covered = test_entities & environment_entities\n",
    "\n",
    "train_missing = train_entities - environment_entities\n",
    "test_missing = test_entities - environment_entities\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COVERAGE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTRAIN dataset:\")\n",
    "print(f\"  Entities WITH environment data: {len(train_covered):,} ({len(train_covered)/len(train_entities)*100:.2f}%)\")\n",
    "print(f\"  Entities WITHOUT environment data: {len(train_missing):,} ({len(train_missing)/len(train_entities)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTEST dataset:\")\n",
    "print(f\"  Entities WITH environment data: {len(test_covered):,} ({len(test_covered)/len(test_entities)*100:.2f}%)\")\n",
    "print(f\"  Entities WITHOUT environment data: {len(test_missing):,} ({len(test_missing)/len(test_entities)*100:.2f}%)\")\n",
    "\n",
    "# Check if there are entities in environment table that aren't in train/test\n",
    "orphan_entities = environment_entities - train_entities - test_entities\n",
    "print(f\"\\nEntities in environment table but NOT in train/test: {len(orphan_entities):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPLICATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(train_missing) > 0 or len(test_missing) > 0:\n",
    "    print(\"\\nâš  IMPORTANT: Some entities don't have environment distribution data!\")\n",
    "    print(\"\\nWhen merging, you have TWO options:\\n\")\n",
    "    \n",
    "    print(\"OPTION 1: Left join + Fill missing values with defaults\")\n",
    "    print(\"  - Use how='left' when merging\")\n",
    "    print(\"  - Fill NaN values with appropriate defaults:\")\n",
    "    print(\"    â€¢ Numeric features (HHI, percentages): 0 or median\")\n",
    "    print(\"    â€¢ Categorical (dominant sector): 'UNKNOWN' or most common\")\n",
    "    print(\"  - Create a 'missing_environment_data' flag feature\")\n",
    "    \n",
    "    print(\"\\nOPTION 2: Inner join (only use entities with complete data)\")\n",
    "    print(\"  - Use how='inner' when merging\")\n",
    "    print(\"  - Loses entities without environment data\")\n",
    "    print(f\"  - Would lose {len(train_missing)} train and {len(test_missing)} test samples\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ RECOMMENDATION:\")\n",
    "    print(\"  Use OPTION 1 (left join + imputation) because:\")\n",
    "    print(\"  - You need to predict ALL test entities\")\n",
    "    print(\"  - Missing environment data itself might be a signal\")\n",
    "    print(\"  - Can't afford to lose test samples\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Perfect coverage! All entities have environment distribution data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a07de76-6984-487e-a7fe-f1b8456f149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>region_code</th>\n",
       "      <th>region_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>revenue</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>environmental_score</th>\n",
       "      <th>social_score</th>\n",
       "      <th>governance_score</th>\n",
       "      <th>target_scope_1</th>\n",
       "      <th>target_scope_2</th>\n",
       "      <th>sdg_id</th>\n",
       "      <th>sdg_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3918</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1.513700e+09</td>\n",
       "      <td>2.770</td>\n",
       "      <td>3.004</td>\n",
       "      <td>2.942</td>\n",
       "      <td>2.143</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10299</td>\n",
       "      <td>WEU</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>FR</td>\n",
       "      <td>France</td>\n",
       "      <td>1.560000e+09</td>\n",
       "      <td>2.501</td>\n",
       "      <td>2.979</td>\n",
       "      <td>2.560</td>\n",
       "      <td>1.571</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2324</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1.238511e+10</td>\n",
       "      <td>3.207</td>\n",
       "      <td>3.776</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.429</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1418</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>3.588600e+09</td>\n",
       "      <td>2.770</td>\n",
       "      <td>3.083</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.929</td>\n",
       "      <td>2659.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1494</td>\n",
       "      <td>NAM</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1.400000e+10</td>\n",
       "      <td>3.383</td>\n",
       "      <td>3.022</td>\n",
       "      <td>4.900</td>\n",
       "      <td>2.214</td>\n",
       "      <td>4319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id region_code       region_name country_code  \\\n",
       "1       3918         NAM  Northern America           US   \n",
       "2      10299         WEU    Western Europe           FR   \n",
       "3       2324         NAM  Northern America           US   \n",
       "7       1418         NAM  Northern America           US   \n",
       "9       1494         NAM  Northern America           US   \n",
       "\n",
       "               country_name       revenue  overall_score  environmental_score  \\\n",
       "1  United States of America  1.513700e+09          2.770                3.004   \n",
       "2                    France  1.560000e+09          2.501                2.979   \n",
       "3  United States of America  1.238511e+10          3.207                3.776   \n",
       "7  United States of America  3.588600e+09          2.770                3.083   \n",
       "9  United States of America  1.400000e+10          3.383                3.022   \n",
       "\n",
       "   social_score  governance_score  target_scope_1  target_scope_2  sdg_id  \\\n",
       "1         2.942             2.143           265.0             0.0     NaN   \n",
       "2         2.560             1.571          1136.0             0.0     NaN   \n",
       "3         3.000             2.429          1468.0             0.0     NaN   \n",
       "7         3.000             1.929          2659.0             0.0     NaN   \n",
       "9         4.900             2.214          4319.0             0.0     NaN   \n",
       "\n",
       "  sdg_name  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "7      NaN  \n",
       "9      NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched = (\n",
    "    train\n",
    "    .merge(sustain, on=\"entity_id\", how=\"left\", indicator=True)\n",
    "    .query(\"_merge == 'left_only'\")\n",
    "    .drop(columns=[\"_merge\"])\n",
    ")\n",
    "\n",
    "print(unmatched.shape)\n",
    "unmatched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0771af-a9ca-4851-8f82-e69dc14d28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line from train dataset:\n",
      "   entity_id region_code     region_name country_code country_name  \\\n",
      "2      10299         WEU  Western Europe           FR       France   \n",
      "\n",
      "        revenue  overall_score  environmental_score  social_score  \\\n",
      "2  1.560000e+09          2.501                2.979          2.56   \n",
      "\n",
      "   governance_score  target_scope_1  target_scope_2  \n",
      "2             1.571          1136.0             0.0  \n",
      "\n",
      "Entries from sustain dataset:\n",
      "    entity_id activity_type activity_code  env_score_adjustment\n",
      "45      10299       End-use     J.58.36.B             -0.226106\n",
      "52      10299     Operation     J.58.45.P              0.226106\n"
     ]
    }
   ],
   "source": [
    "# Extract the line from train where entity_id is 47\n",
    "train_line = train[train['entity_id'] == 10299]\n",
    "\n",
    "# Extract all entries from sustain where entity_id is 47\n",
    "environment_entries = environment[environment['entity_id'] == 10299]\n",
    "\n",
    "# Display the results\n",
    "print(\"Line from train dataset:\")\n",
    "print(train_line)\n",
    "print(\"\\nEntries from sustain dataset:\")\n",
    "print(environment_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f989285-2f91-4aec-88a8-f2c7e8e581b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique activity types: 8\n",
      "Unique activity types: ['Transportation' 'Operation' 'End-use' 'Farming' 'Manufacturing'\n",
      " 'Raw materials' 'Disposal\\xa0' 'Other']\n",
      "Number of unique activity codes: 91\n",
      "Unique activity codes: ['M.70.4.P' 'MTH002' 'J.58.16.B' 'J.58.20.P' 'H.51.1.B' 'A.1.5.B'\n",
      " 'D.35.7.B' 'D.35.15.P' 'I.56.1.B' 'J.63.5.B' 'H.49.6.B' 'C.21.9.B'\n",
      " 'C.20.26.B' 'C.28.1.P' 'C.28.94.P' 'C.29.6.B' 'C.29.10.B' 'C.14.45.B'\n",
      " 'C.14.34.P' 'MTH003' 'X.XX.3.B' 'MTH001' 'C.32.47.B' 'C.32.34.B'\n",
      " 'C.32.3.B' 'M.74.2.B' 'J.58.36.B' 'J.58.94.P' 'J.58.45.P' 'L.68.6.B'\n",
      " 'G.47.44.B' 'G.47.4.B' 'M.75.2.P' 'H.50.62.B' 'I.55.06.B' 'F.42.15.B'\n",
      " 'F.42.12.P' 'F.42.41.B' 'A.1.4.B' 'C.11.2.B' 'C.20.3.B' 'C.26.1.B'\n",
      " 'C.27.75.B' 'C.27.70.B' 'C.27.78.P' 'C.27.91.P' 'C.27.52.P' 'C.25.06.P'\n",
      " 'C.28.31.P' 'C.28.81.P' 'C.14.20.B' 'C.32.41.B' 'C.32.78.P' 'C.32.63.P'\n",
      " 'J.58.101.B' 'H.50.73.B' 'A.1.3.B' 'C.14.30.B' 'C.14.87.P' 'C.20.1.P'\n",
      " 'C.22.34.B' 'C.26.38.P' 'C.26.55.P' 'C.27.12.P' 'C.27.61.P' 'C.27.46.P'\n",
      " 'C.28.33.P' 'C.28.56.P' 'C.28.40.P' 'C.32.4.B' 'C.32.1.P' 'D.35.8.B'\n",
      " 'E.38.34.B' 'E.38.24.B' 'J.61.2.B' 'J.61.99.B' 'Q.86.2.B' 'Q.86.1.P'\n",
      " 'MTH004' 'C.14.01.B' 'C.17.1.B' 'C.17.2.B' 'ENVIB010' 'ENVIB025'\n",
      " 'ENVIB050' 'H.51.4.B' 'M.70.5.P' 'I.56.1.P' 'L.68.3.B' 'A.1.6.B'\n",
      " 'L.68.7.B']\n"
     ]
    }
   ],
   "source": [
    "#find the number of unique activity_type and activity_code\n",
    "num_activity_types = environment['activity_type'].nunique()\n",
    "unique_activity_types = environment['activity_type'].unique()\n",
    "\n",
    "print(\"Number of unique activity types:\", num_activity_types)\n",
    "print(\"Unique activity types:\", unique_activity_types)\n",
    "\n",
    "# num_activity_codes = environment['activity_code'].nunique()\n",
    "# unique_activity_codes = environment['activity_code'].unique()\n",
    "\n",
    "# print(\"Number of unique activity codes:\", num_activity_codes)\n",
    "# print(\"Unique activity codes:\", unique_activity_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6328a-b66a-482d-a6d2-5d4d683d7f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
